var documenterSearchIndex = {"docs":
[{"location":"api/","page":"API","title":"API","text":"Modules = [QuantumPrisonersDilemmaModel]\nOrder   = [:type, :function]\nPrivate = false","category":"page"},{"location":"api/#QuantumPrisonersDilemmaModel.QPDM","page":"API","title":"QuantumPrisonersDilemmaModel.QPDM","text":"QPDM{T<:Real} <: AbstractQPDM\n\nA model object for the Quantum Prisoner's Dilemma Model. The QPDM has four basis states:\n\nopponent defects and you defect \nopponent defects and you cooperate \nopponent cooperates and you defect \nopponent cooperates and you cooperate\n\nThe bases are orthonormal and in standard form. The model assumes three conditions:\n\nPlayer 1 (you) is told that player 2 defected\nPlayer 1 (you) is told that player 2 cooperated\nPlayer 1 (you) is not informed of player's action\n\nModel inputs and outputs are assumed to be in the order above. \n\nFields\n\nμd: utility for defecting \nμc: utility for cooperating \nγ: entanglement parameter for beliefs and actions \n\nExample\n\nusing QuantumPrisonersDilemmaModel\nmodel = QPDM(;μd=.51, γ=2.09)\n\nReferences\n\nPothos, E. M., & Busemeyer, J. R. (2009). A quantum probability explanation for violations of ‘rational’decision theory. Proceedings of the Royal Society B: Biological Sciences, 276(1665), 2171-2178.\n\n\n\n\n\n","category":"type"},{"location":"api/#Base.rand-Tuple{QuantumPrisonersDilemmaModel.AbstractQPDM, Int64}","page":"API","title":"Base.rand","text":"rand(dist::AbstractQPDM, n::Int; t = π / 2)\n\nGenerates simulated data for the following conditions:\n\nPlayer 1 is told that player 2 defected\nPlayer 1 is told that player 2 cooperated\nPlayer 1 is not informed of player's action\n\nArguments\n\ndist::AbstractQPDM\nn: the number of trials per condition \n\nKeywords\n\nt = π / 2: time of decision\n\nExample\n\nusing QuantumPrisonersDilemmaModel \nmodel = QPDM(;μd=.51, γ=2.09)\ndata = rand(model, 100)\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.logpdf-Tuple{QuantumPrisonersDilemmaModel.AbstractQPDM, Int64, Vector{Int64}}","page":"API","title":"Distributions.logpdf","text":"logpdf(dist::AbstractQPDM, n::Int, n_d::Vector{Int}; t = π / 2)\n\nReturns the joint log density given data for the following conditions:\n\nPlayer 1 is told that player 2 defected\nPlayer 1 is told that player 2 cooperated\nPlayer 1 is not informed of player's action\n\nArguments\n\ndist::AbstractQPDM\nn: the number of trials per condition \nn_d: the number of defections in each condition \n\nKeywords\n\nt = π / 2: time of decision\n\nExample\n\nusing QuantumPrisonersDilemmaModel \nmodel = QPDM(;μd=.51, γ=2.09)\nn_trials = 100\ndata = rand(model, n_trials)\nlogpdf(model, n_trials, data)\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.pdf-Tuple{QuantumPrisonersDilemmaModel.AbstractQPDM, Int64, Vector{Int64}}","page":"API","title":"Distributions.pdf","text":"pdf(dist::AbstractQPDM, n::Int, n_d::Vector{Int}; t = π / 2)\n\nReturns the joint probability density given data for the following conditions:\n\nPlayer 1 is told that player 2 defected\nPlayer 1 is told that player 2 cooperated\nPlayer 1 is not informed of player's action\n\nArguments\n\ndist::AbstractQPDM\nn: the number of trials per condition \nn_d: the number of defections in each condition \n\nKeywords\n\nt = π / 2: time of decision\n\n\n\n\n\n","category":"method"},{"location":"api/#QuantumPrisonersDilemmaModel.predict-Tuple{QuantumPrisonersDilemmaModel.AbstractQPDM}","page":"API","title":"QuantumPrisonersDilemmaModel.predict","text":"predict(dist::AbstractQPDM; t = π / 2)\n\nReturns predicted response probability for the following conditions:\n\nPlayer 1 is told that player 2 defected\nPlayer 1 is told that player 2 cooperated\nPlayer 1 is not informed of player's action\n\nArguments\n\ndist::AbstractQPDM\n\nKeywords\n\nt = π / 2: time of decision\n\nExample\n\nusing QuantumPrisonersDilemmaModel \nmodel = QPDM(;μd=.51, γ=2.09)\npredict(model)\n\n\n\n\n\n","category":"method"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"warning: Warning\nThis page is under construction.","category":"page"},{"location":"model_description/#Introduction","page":"Model Description","title":"Introduction","text":"","category":"section"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"In this tutorial, we present a quantum cognition model of interference effect's in the prisoner's dilemma. The goal is to provide a conceptual understanding of the model and how it produces interference effects. Before introducing the model, we will briefly describe the Prisoner's dilemma and the interference effect.  ","category":"page"},{"location":"model_description/#The-Prisoner's-Dilemma","page":"Model Description","title":"The Prisoner's Dilemma","text":"","category":"section"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"The prisoner's dilemma (PD) is a two person interdependent decision making task from game theory. In a typical version of the PD, two players decide simultanouesly (i.e., without knowing the decision of the other) to cooperate or defect. The payoff each player recieves depends on both his or her choice and the choice of the other player. A typical payoff matrix is presented in the table below where entries (x_1x_2) correspond to the payoff given to player 1 and player 2, respectively. Assuming rational, self-interested players, the Nash equalibrium occurs when both players defect. Even though cooperating would lead to a better collective outcome (20 vs. 10), each individual has the incentive to defect. For example, if player 2 cooperates, player 1 recieves a better payoff by defecting (25 vs. 20). Alternatively, if player 2 defects, player 1 also recieves a better payoff by defecting (10 vs. 5).  ","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"<style type=\"text/css\">\n.tg  {border-collapse:collapse;border-spacing:0;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-0lax{text-align:left;vertical-align:top}\n</style>\n<table class=\"tg\">\n<thead>\n  <tr>\n    <th class=\"tg-0lax\" colspan=\"2\" rowspan=\"2\"></th>\n    <th class=\"tg-0lax\" colspan=\"2\">Player 2 (you)</th>\n  </tr>\n  <tr>\n    <th class=\"tg-0lax\">Defect</th>\n    <th class=\"tg-0lax\">Cooperate</th>\n  </tr>\n</thead>\n<tbody>\n  <tr>\n    <td class=\"tg-0lax\" rowspan=\"2\">Player 1</td>\n    <td class=\"tg-0lax\">Defect</td>\n    <td class=\"tg-0lax\">(10,10)</td>\n    <td class=\"tg-0lax\">(25,5)</td>\n  </tr>\n  <tr>\n    <td class=\"tg-0lax\">Cooperate</td>\n    <td class=\"tg-0lax\">(5,25)</td>\n    <td class=\"tg-0lax\">(20,20)</td>\n  </tr>\n</tbody>\n</table>","category":"page"},{"location":"model_description/#Interference-Effect","page":"Model Description","title":"Interference Effect","text":"","category":"section"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"The interference effect occurs when decisions in the PD violate the law of total probability. Consider an experiment of the prisoner's dilemma with three conditions:","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"Player 2 is told that player 1 defected: R_2=d\nPlayer 2 is told that player 1 cooperated: R_2=c\nPlayer 2 is not informed of player's action","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"The law of total probability requires:","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"Pr(R_2=d) = Pr(R_2=d mid R_1=d) Pr(R_1=d) + Pr(R_2=d mid R_1=c) Pr(R_1=c)","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"where the left hand side corresponds to condition 3 and the terms on the right hand side correspond to conditions 1 and 2, respectively. When this inequality does not hold, an interference effect occurs. ","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"An important property of the law of total probability is that it requires condition 3 to be a weighted average of conditions 1 and 2. This implies the following ordering of terms:","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"min(Pr(R_2=d mid R_1=d) Pr(R_2=d mid R_1=c)) leq Pr(R_2=d) leq max(Pr(R_2=d mid R_2=1) Pr(R_2=d mid R_1=c))","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"which is violated in human decision making, leading to an interference effect. The results below show a typical response pattern:","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"Condition Formula Data Model\n1 Pr(R_1=d mid R_2=d) .84 .81\n2 Pr(R_1=d mid R_2=c) .66 .65\n3 Pr(R_1=d) .55 .57","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"An interference effect is present in the data because the response probability in condition 3 is below the response probabilities in conditions 1 and 2. The predictions of the quantum model are shown in the last column.","category":"page"},{"location":"model_description/#Quantum-Model","page":"Model Description","title":"Quantum Model","text":"","category":"section"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"quantum prisoner's dilemma model (QPDM)","category":"page"},{"location":"model_description/#Bases","page":"Model Description","title":"Bases","text":"","category":"section"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"The QPDM consists of four basis states respesenting the four possible outcomes for defect (D) and cooperate (C):","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"mathbfB = kettextrmDDkettextrmDCkettextrmCDkettextrmCC","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"where basis ketij repesents the outcome in which the opponent chooses i and you choose j. We will assume mathbfB is the standard basis, meaning each basis vector consists of a 1 with all other elements equal to zero, e.g., ","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"kettextrmDD = beginbmatrix\n\t1  \n\t0  \n\t0  \n\t0 \nendbmatrix","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"Combining the basis vectors into a single matrix, we get the identity matrix:","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"mathbfI_4 = beginbmatrix\t\t\n\t1  0  0  0\n\t0  1  0  0\n\t0  0  1  0\n\t0  0  0  1\nendbmatrix","category":"page"},{"location":"model_description/#States","page":"Model Description","title":"States","text":"","category":"section"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"The state of the cognitive system is a superposition (i.e. linear combination) over basis states:","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"ketboldsymbolpsi = alpha_textrmDD kettextrmDD+ alpha_textrmDC kettextrmDC+ alpha_textrmCD kettextrmCD+ alpha_textrmCC kettextrmCC","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"where lVertketboldsymbolpsi rVert = 1. The coefficients can be written as:","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"boldsymbolalpha = beginbmatrix\n\talpha_textrmDD  \n\talpha_textrmDC  \n\talpha_textrmCD  \n\talpha_textrmCC  \nendbmatrix","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"The QPDM assumes the initial state of the decision maker is a uniform superposition over basis states: ","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"ketboldsymbolpsi_0 = frac12beginbmatrix\n\t1  \n\t1  \n\t1  \n\t1  \nendbmatrix","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"In conditions 1 and 2, the state is updated upon learning the decision of player 1: ketboldsymbolpsi_0 rightarrow ketboldsymbolpsi_kk in cd. When player 2 is told that player 1 defected, the state vector becomes:","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"ketboldsymbolpsi_d = frac1sqrt2beginbmatrix\n\t1  \n\t1  \n\t0  \n\t0  \nendbmatrix","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"indicating that the state collapsed onto the sub-space representing player 1 defected. Similarly, when player 2 is told that player 1 cooperated, the state collapses to the sub-space represnting the event player 1 cooperated, giving: ","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"ketboldsymbolpsi_c = frac1sqrt2beginbmatrix\n\t0  \n\t0  \n\t1  \n\t1  \nendbmatrix","category":"page"},{"location":"model_description/#Hamiltonian-Matrices","page":"Model Description","title":"Hamiltonian Matrices","text":"","category":"section"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"Hamiltonian matrices govern the decision dynamics of the model. The Hamiltonian matrix mathbfH consists of two components: mathbfH_A is sensitive to the payoff matrix, and mathbfH_B is sensitive to cognitive dissonance between beliefs and actions. The component mathbfH_A is defined as follows: ","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"mathbfH_A = beginbmatrix\t\t\n\tmathbfH_A_d  mathbf0\n\tmathbf0  mathbfH_A_c\nendbmatrix","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"where","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"mathbfH_A_k = frac1sqrt1 + mu_k^2beginbmatrix\t\t\n\tmu_k  1\n\t1  -mu_k\nendbmatrix","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"<details>\n<summary><b>Show Code</b></summary>","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"using Plots \nprob_defect(μ, t) = .5 + (μ / (1 + μ^2)) * sin((π * t) / 2)^2\nμs = range(-1, 1, length=5)\nts = range(0, π / 2, length=100)\nplot_Ha = plot(ts, map(μ -> prob_defect.(μ, ts), μs), grid=false, label=μs', \n\txlabel=\"Time\", ylabel=\"Probability Defect\", legendtitle=\"μ\")\nnothing","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"</details>","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"plot_Ha","category":"page"},{"location":"model_description/#Action-Selection","page":"Model Description","title":"Action Selection","text":"","category":"section"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"mathbfP_d = kettextrmDD bratextrmDD + kettextrmDC bratextrmDC = beginbmatrix\t\t\n\t1  0  0  0\n\t0  0  0  0\n\t0  0  1  0\n\t0  0  0  0\nendbmatrix","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"The unitary transformation matrix is given by: mathbfU = e^-i cdot t cdot  mathbfH","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"with t=fracpi2, which maximizes the amplitude of the waveform. ","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"Pr(R_2=d mid R_1=d) = lVertmathbfP_d mathbfU ketpsi_drVert^2","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"Pr(R_2=d mid R_1=c) = lVertmathbfP_d mathbfU ketpsi_crVert^2","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"Pr(R_2=d) = lVertmathbfP_d mathbfU ketpsi_0rVert^2","category":"page"},{"location":"model_description/#QPDM-Predictions","page":"Model Description","title":"QPDM Predictions","text":"","category":"section"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"As a simple example, the code block illustrates how to generate the predictions in the table above. The first parameter mu_d is the utility for defecting. When no value is passed for the utility of cooperating, mu_d = mu_c. The parameter gamma is the entanglement parameter which aligns beliefs about the opponents action and one's own action. ","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"using QuantumPrisonersDilemmaModel\nmodel = QPDM(;μd=.51, γ=2.09)\npreds = predict(model)","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"<details>\n<summary><b>Show Code</b></summary>","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"using Plots \nusing QuantumPrisonersDilemmaModel \n\nfunction compute_IE(;μ, γ) \n\tpreds = predict(QPDM(;μd=μ, γ)) \n\tif preds[3] < minimum(preds[1:2])\n\t\treturn preds[3] - minimum(preds[1:2])\n\telseif preds[3] > maximum(preds[1:2]) \n\t\treturn preds[3] - maximum(preds[1:2])\n\tend\n\treturn 0.0\nend\n\nmap_mu(;μs, γ) = map(μ -> compute_IE(;μ, γ), μs)\n\ncompute_IE(;μ=.5, γ=2) \nμs = range(-1, 1, length=100)\nγs = range(-2, 2, length=5)\n\nIEs = map(γ -> map_mu(;μs, γ), γs)\n\ncontour_plot1 = plot(μs, IEs, grid=false, label=γs', \n\txlabel=\"μ\", ylabel=\"Interference Effect\", legendtitle=\"γ\", legend=:outerright)\nnothing","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"</details>","category":"page"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"contour_plot1","category":"page"},{"location":"model_description/#References","page":"Model Description","title":"References","text":"","category":"section"},{"location":"model_description/","page":"Model Description","title":"Model Description","text":"Pothos, E. M., & Busemeyer, J. R. (2009). A quantum probability explanation for violations of ‘rational’decision theory. Proceedings of the Royal Society B: Biological Sciences, 276(1665), 2171-2178.","category":"page"},{"location":"overview/#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"This page provides an overview of the API along with examples. ","category":"page"},{"location":"overview/#Make-Predictions","page":"Overview","title":"Make Predictions","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"The quantum prisoner's dilemma model (QPDM) generates predictions for three conditions:","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"Player 1 is told that player 2 defected\nPlayer 1 is told that player 2 cooperated\nPlayer 1 is not informed of player's action","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"using QuantumPrisonersDilemmaModel \nmodel = QPDM(;μd=.51, γ=2.09)\npredict(model)","category":"page"},{"location":"overview/#Simulate-Model","page":"Overview","title":"Simulate Model","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"The code block below demonstrates how to generate simulated data from the model using rand. In the example, we will generate 100 simulated trials for each condition. ","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"using QuantumPrisonersDilemmaModel \nmodel = QPDM(;μd=.51, γ=2.09)\ndata = rand(model, 100)","category":"page"},{"location":"overview/#Evaluate-Log-Likelihood","page":"Overview","title":"Evaluate Log Likelihood","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"The log likelihood of data can be evaluated using logpdf. In the code block below, we generate simulated data and evaluate the logpdf: ","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"using QuantumPrisonersDilemmaModel \nmodel = QPDM(;μd=.51, γ=2.09)\nn_trials = 100\ndata = rand(model, n_trials)\nlogpdf(model, n_trials, data)","category":"page"},{"location":"#QuantumPrisonersDilemmaModel.jl","page":"Home","title":"QuantumPrisonersDilemmaModel.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package contains code for a quantum cognition model of inteference effects in the prisoner's dilemma. ","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package is not registered in Julia's general registry. However, there two ways you can install the package. Option 1 is to install without version control. In the REPL, use ] to switch to the package mode and enter the following:","category":"page"},{"location":"","page":"Home","title":"Home","text":"add https://github.com/itsdfish/QuantumPrisonersDilemmaModel.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"Option 2 is to install via a custom registry. The advantage of this approach is that you have more control over version control, expecially if you are using a project-specfic environment. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Install the registry using the directions found here.\nAdd the package by typing ] into the REPL and then typing (or pasting):","category":"page"},{"location":"","page":"Home","title":"Home","text":"add QuantumPrisonersDilemmaModel","category":"page"},{"location":"#References","page":"Home","title":"References","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pothos, E. M., & Busemeyer, J. R. (2009). A quantum probability explanation for violations of ‘rational’decision theory. Proceedings of the Royal Society B: Biological Sciences, 276(1665), 2171-2178.","category":"page"}]
}
